{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4CHM1Cb8zheCAFDQVHrAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mroshan454/Replicating-ViT-Research-Paper/blob/main/Modular_Functions_For_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modular Code Structure for ViT Replication\n",
        "\n",
        "This notebook explains the modular Python Scripts used in My Vision Transformer (ViT) Replication Project. Each Script is written to handle a specific part of the machine learning pipeline in a clear , reusable way - just like in the production codebases.\n"
      ],
      "metadata": {
        "id": "E9eLpoywI3zp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. üì¶`data_setup.py` - Dataset and Dataloader Builder\n",
        "\n",
        "**Purpose** - This script helps in loading the image data into PyTorch `Dataloaders's`. It is written modularly so that it can be reused with any image classification dataset , simply by passing in the paths.\n",
        "\n"
      ],
      "metadata": {
        "id": "ybQVox53LA4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_setup.py\n",
        "\"\"\"\n",
        "This file contains functionality for creating PyTorch DataLoader's for\n",
        "image classification data\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import dataloader\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_data:str,\n",
        "    test_data:str,\n",
        "    transform:transforms.Compose,\n",
        "    batch_size:int,\n",
        "    num_workers:int=NUM_WORKERS\n",
        "    ):\n",
        "    \"\"\"Creates training and testing DataLoaders.\n",
        "    Takes in a training directory and testing directory path and turns\n",
        "    them into PyTorch Datasets and them into PyTorch Dataloader.\n",
        "\n",
        "    Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    transform: torchvision transforms to perform on training and testing data.\n",
        "    batch_size: Number of samples per batch in each of the Dataloaders.\n",
        "    num_workers: An integer for number of workers per DataLoader.\n",
        "\n",
        "    Returns:\n",
        "    A tuple of (train_dataloader,test_dataloader ,class_names).\n",
        "    Where class_names is a list of the target classes.\n",
        "    Example usage:\n",
        "    train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir=path/to/train_dir,\n",
        "    test_dir = path/to/test_dir,\n",
        "    transform=some_transform,\n",
        "    batch_size=32,\n",
        "    num_workers=4)\n",
        "    \"\"\"\n",
        "    #Use ImageFolder to create dataset(s)\n",
        "    train_data = datasets.ImageFolder(train_dir,transform=transform)\n",
        "    test_data = datasets.ImageFolder(test_dir,transform=transform)\n",
        "    #Get Class Names\n",
        "    class_names = train_data.classes\n",
        "    #Turn images into DataLoaders\n",
        "    train_dataloader = DataLoader(train_data,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=True,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=True)\n",
        "    test_dataloader = Dataloader(test_data,\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=False,\n",
        "                                 num_workers=num_workers,\n",
        "                                 pin_memory=True)\n",
        "    return train_dataloader , test_dataloader , class_names"
      ],
      "metadata": {
        "id": "s_Yj0d9ILAoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ‚öôÔ∏è`engine.py` - Training and Evaluation Engine\n",
        "\n",
        "This script contains all training and evaluation logic for the model. It include modular functions for:\n",
        "* One-epoch training(`train_step`)\n",
        "* One-epoch testing(`test_step`)\n",
        "* Full training Pipeline over multiple epochs(`train`)"
      ],
      "metadata": {
        "id": "a4YmgH54K_-W"
      }
    }
  ]
}